{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMYl41Z4GPU5/slKYNOTqbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engelberger/von-mises/blob/main/von_mises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IijCKTGT6w1w"
      },
      "outputs": [],
      "source": [
        "!pip install -qq git+https://github.com/engelberger/von-mises.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/engelberger/von-mises.git"
      ],
      "metadata": {
        "id": "SthdJNnK7ZEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd von-mises/"
      ],
      "metadata": {
        "id": "PzLssn-Q7fXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!SETUPTOOLS_SCM_PRETEND_VERSION=0.1.0 python -m pip install -qq -e \".[dev]\""
      ],
      "metadata": {
        "id": "_oTkLIKz7EGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "cxQQf46YDp0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JAX von Mises Sampling: Performance Showcase\n",
        "\n",
        "This notebook demonstrates the dramatic performance improvements achieved using JAX's Just-In-Time (JIT) compilation with the von Mises sampling library.\n",
        "\n",
        "## What is the von Mises Distribution?\n",
        "\n",
        "The von Mises distribution is a probability distribution on the circle. It's often described as the circular analog of the normal distribution and is widely used for modeling angles, directions, and cyclic data in fields like:\n",
        "\n",
        "- **Bioinformatics**: Protein dihedral angles\n",
        "- **Computer Vision**: Object orientation and pose estimation\n",
        "- **Geoscience**: Wind directions and geological orientations\n",
        "- **Robotics**: Direction of movement and orientation\n",
        "\n",
        "## The JAX von Mises Library\n",
        "\n",
        "Our `jax-von-mises` library implements the Best-Fisher algorithm for sampling from the von Mises distribution, with full compatibility with JAX transformations (jit, vmap, pmap). This makes it:\n",
        "\n",
        "- **Fast**: Optimized for high-performance computation\n",
        "- **GPU/TPU-compatible**: Runs efficiently on accelerator hardware\n",
        "- **Parallelizable**: Works with JAX's vectorization and parallelization tools\n",
        "- **Neural network-friendly**: Easily integrates with JAX-based ML frameworks"
      ],
      "metadata": {
        "id": "xSCdg0r8IJVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Imports\n",
        "\n",
        "First, let's import the necessary libraries:"
      ],
      "metadata": {
        "id": "zcrCLVVxIPAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from functools import partial\n",
        "\n",
        "# Set better plotting style\n",
        "plt.style.use('ggplot')\n",
        "sns.set_context(\"notebook\", font_scale=1.5)\n",
        "\n",
        "# Print JAX and device information\n",
        "print(f\"JAX version: {jax.__version__}\")\n",
        "print(f\"Available devices: {jax.devices()}\")\n",
        "\n",
        "# Import the von Mises sampling library\n",
        "try:\n",
        "    from jax_von_mises import sample_von_mises, vmises_log_prob, vmises_entropy\n",
        "    from jax_von_mises.sampler import compute_p\n",
        "    print(\"Successfully imported von Mises sampling functions\")\n",
        "except ImportError:\n",
        "    print(\"Warning: jax_von_mises package not found. Installing in development mode...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"])\n",
        "    from jax_von_mises import sample_von_mises, vmises_log_prob, vmises_entropy\n",
        "    from jax_von_mises.sampler import compute_p\n",
        "    print(\"Successfully installed and imported von Mises sampling functions\")\n"
      ],
      "metadata": {
        "id": "-nw8dX2zIN_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Basic Sampling Demonstration\n",
        "\n",
        "Let's start by demonstrating how to sample from a von Mises distribution:\n"
      ],
      "metadata": {
        "id": "l6QhXPSMIWlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "key = random.PRNGKey(42)\n",
        "\n",
        "# Parameters for the von Mises distribution\n",
        "loc = 0.0  # Mean direction (in radians)\n",
        "concentration = 5.0  # Higher values = more concentrated around the mean\n",
        "\n",
        "# Generate samples (without JIT first)\n",
        "n_samples = 10000\n",
        "samples = sample_von_mises(key, loc, concentration, shape=(n_samples,))\n",
        "\n",
        "# Plot the histogram of samples\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(samples, bins=50, density=True, alpha=0.6, color='steelblue')\n",
        "plt.title(f'Von Mises Distribution (μ={loc}, κ={concentration})')\n",
        "plt.xlabel('Angle (radians)')\n",
        "plt.ylabel('Density')\n",
        "plt.axvline(x=loc, color='r', linestyle='--', label='Mean direction')\n",
        "plt.xlim(-np.pi, np.pi)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hIpkz7H_IZAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. JIT vs. Non-JIT Performance Comparison\n",
        "\n",
        "Now, let's compare the performance of JIT-compiled sampling with non-JIT sampling:\n"
      ],
      "metadata": {
        "id": "CrczkQfMIc-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to measure sampling time\n",
        "def measure_sampling_time(sampling_fn, key, loc, concentration, shape, n_runs=5):\n",
        "    \"\"\"Measure the time taken to sample from the von Mises distribution.\"\"\"\n",
        "    # Warmup call (to trigger compilation if needed)\n",
        "    _ = sampling_fn(key, loc, concentration, shape)\n",
        "\n",
        "    # Actual timing\n",
        "    start_time = time.time()\n",
        "    for i in range(n_runs):\n",
        "        subkey = random.fold_in(key, i)\n",
        "        samples = sampling_fn(key, loc, concentration, shape)\n",
        "        # Force completion of any asynchronous operations\n",
        "        samples.block_until_ready()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate average time per sample\n",
        "    total_time = end_time - start_time\n",
        "    time_per_sample = total_time / (n_runs * shape[0])\n",
        "    samples_per_second = (n_runs * shape[0]) / total_time\n",
        "\n",
        "    return {\n",
        "        'total_time': total_time,\n",
        "        'time_per_sample': time_per_sample,\n",
        "        'samples_per_second': samples_per_second\n",
        "    }\n",
        "\n",
        "# Define test parameters\n",
        "sample_sizes = [100, 1000, 10000, 100000]\n",
        "n_runs = 3  # Number of repeated runs\n",
        "\n",
        "# Create results storage\n",
        "results = []\n",
        "\n",
        "# JIT-compiled function with correct static_argnums\n",
        "jitted_sampler = jax.jit(sample_von_mises, static_argnums=(3,))\n",
        "\n",
        "print(\"Testing JIT vs. non-JIT performance...\")\n",
        "\n",
        "for size in sample_sizes:\n",
        "    shape = (size,)\n",
        "    print(f\"\\nSample size: {size}\")\n",
        "\n",
        "    # Measure non-JIT performance for smaller sizes\n",
        "    if size <= 10000:\n",
        "        print(\"  Measuring non-JIT performance...\")\n",
        "        non_jit_result = measure_sampling_time(sample_von_mises, key, loc, concentration, shape, n_runs=n_runs)\n",
        "        results.append({\n",
        "            'Sample Size': size,\n",
        "            'Method': 'Non-JIT',\n",
        "            'Samples/Second': non_jit_result['samples_per_second'],\n",
        "            'Time/Sample (ms)': non_jit_result['time_per_sample'] * 1000\n",
        "        })\n",
        "        print(f\"  Non-JIT: {non_jit_result['samples_per_second']:.0f} samples/second\")\n",
        "\n",
        "    # Measure JIT performance for all sizes\n",
        "    print(\"  Measuring JIT performance...\")\n",
        "    jit_result = measure_sampling_time(jitted_sampler, key, loc, concentration, shape, n_runs=n_runs)\n",
        "    results.append({\n",
        "        'Sample Size': size,\n",
        "        'Method': 'JIT',\n",
        "        'Samples/Second': jit_result['samples_per_second'],\n",
        "        'Time/Sample (ms)': jit_result['time_per_sample'] * 1000\n",
        "    })\n",
        "    print(f\"  JIT: {jit_result['samples_per_second']:.0f} samples/second\")\n",
        "\n",
        "    # Calculate speedup if we have both measurements\n",
        "    if size <= 10000:\n",
        "        speedup = non_jit_result['time_per_sample'] / jit_result['time_per_sample']\n",
        "        print(f\"  Speedup: {speedup:.1f}x\")\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nResults summary:\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "g_kIWnOJIgq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Visualization of JIT Performance Benefits\n",
        "\n",
        "Let's create some visualizations to showcase the performance improvements:"
      ],
      "metadata": {
        "id": "8vUHhNv3IlA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bar chart comparing JIT vs. non-JIT for different sample sizes\n",
        "plt.figure(figsize=(14, 8))\n",
        "subset_df = df[df['Sample Size'] <= 10000].copy()  # Only where we have both measurements\n",
        "subset_df['Sample Size'] = subset_df['Sample Size'].astype(str)  # Convert to string for categorical plotting\n",
        "\n",
        "ax = sns.barplot(x='Sample Size', y='Samples/Second', hue='Method', data=subset_df, palette=['lightcoral', 'steelblue'])\n",
        "\n",
        "# Add text labels for speedup\n",
        "for i in range(0, len(subset_df), 2):\n",
        "    if i+1 < len(subset_df):\n",
        "        non_jit = subset_df.iloc[i]['Samples/Second']\n",
        "        jit = subset_df.iloc[i+1]['Samples/Second']\n",
        "        speedup = jit / non_jit\n",
        "        ax.text(i//2, jit*1.05, f\"{speedup:.1f}x faster\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.title('JAX von Mises Sampling Performance: JIT vs. Non-JIT')\n",
        "plt.ylabel('Samples per Second (higher is better)')\n",
        "plt.yscale('log')  # Log scale for better visualization\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/jit_vs_nonjit_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved JIT vs non-JIT comparison plot to figures/jit_vs_nonjit_comparison.png\")\n",
        "plt.show()  # Comment out interactive display"
      ],
      "metadata": {
        "id": "Rd7GUaB3Ioex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Line chart showing scalability with sample size\n",
        "plt.figure(figsize=(14, 8))\n",
        "df_jit = df[df['Method'] == 'JIT']\n",
        "\n",
        "sns.lineplot(x='Sample Size', y='Samples/Second', data=df_jit, marker='o', markersize=10, linewidth=3, color='steelblue')\n",
        "plt.title('JIT Sampling Performance Scaling with Sample Size')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('Samples per Second (higher is better)')\n",
        "plt.xscale('log')  # Log scale for x-axis\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/sample_size_scaling.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved sample size scaling plot to figures/sample_size_scaling.png\")\n",
        "plt.show()  # Comment out interactive display"
      ],
      "metadata": {
        "id": "ufgVGmtQIsqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Effect of Concentration Parameter on Performance\n",
        "\n",
        "The concentration parameter (κ) affects sampling performance. Let's visualize this relationship:"
      ],
      "metadata": {
        "id": "enPVC-A9IwFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test performance with different concentration values\n",
        "concentration_values = [0.1, 1.0, 5.0, 10.0, 50.0, 100.0]\n",
        "concentration_results = []\n",
        "\n",
        "sample_size = 10000\n",
        "shape = (sample_size,)\n",
        "n_runs = 3\n",
        "\n",
        "print(\"Testing performance with different concentration values...\")\n",
        "\n",
        "for kappa in concentration_values:\n",
        "    print(f\"  Testing κ={kappa}...\")\n",
        "    jit_result = measure_sampling_time(jitted_sampler, key, loc, kappa, shape, n_runs=n_runs)\n",
        "    concentration_results.append({\n",
        "        'Concentration': kappa,\n",
        "        'Samples/Second': jit_result['samples_per_second'],\n",
        "        'Time/Sample (ms)': jit_result['time_per_sample'] * 1000\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "df_concentration = pd.DataFrame(concentration_results)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.lineplot(x='Concentration', y='Samples/Second', data=df_concentration, marker='o', markersize=10, linewidth=3, color='steelblue')\n",
        "plt.title('Effect of Concentration Parameter on Sampling Performance')\n",
        "plt.xlabel('Concentration (κ)')\n",
        "plt.ylabel('Samples per Second (higher is better)')\n",
        "plt.xscale('log')  # Log scale for x-axis\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/concentration_impact_performance.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved concentration impact plot to figures/concentration_impact_performance.png\")\n",
        "plt.show()  # Comment out interactive display"
      ],
      "metadata": {
        "id": "0BS89rxjIzpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Batch Processing with vmap\n",
        "\n",
        "JAX's vectorization with `vmap` provides another performance boost when processing multiple distributions simultaneously:\n"
      ],
      "metadata": {
        "id": "qS2Pp5mWI20u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to sample from von Mises with fixed shape\n",
        "def sample_fn(key, loc, concentration):\n",
        "    return sample_von_mises(key, loc, concentration, shape=(1000,))\n",
        "\n",
        "# Create a batched version with vmap\n",
        "batched_sample_fn = jax.vmap(sample_fn, in_axes=(0, 0, 0))\n",
        "\n",
        "# Jit-compile the batched function\n",
        "jitted_batched_fn = jax.jit(batched_sample_fn)\n",
        "\n",
        "# Test with different batch sizes\n",
        "batch_sizes = [1, 10, 50, 100]\n",
        "batch_results = []\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    print(f\"Testing batch size {batch_size}...\")\n",
        "\n",
        "    # Create batch inputs\n",
        "    batch_keys = random.split(key, batch_size)\n",
        "    batch_locs = jnp.linspace(-jnp.pi/2, jnp.pi/2, batch_size)\n",
        "    batch_concentrations = jnp.ones(batch_size) * 5.0\n",
        "\n",
        "    # Warmup\n",
        "    _ = jitted_batched_fn(batch_keys, batch_locs, batch_concentrations)\n",
        "\n",
        "    # Measure batched performance\n",
        "    start_time = time.time()\n",
        "    for i in range(n_runs):\n",
        "        fold_key = random.fold_in(key, i)\n",
        "        batch_keys = random.split(fold_key, batch_size)\n",
        "        samples = jitted_batched_fn(batch_keys, batch_locs, batch_concentrations)\n",
        "        samples.block_until_ready()\n",
        "    batch_time = time.time() - start_time\n",
        "\n",
        "    # Calculate samples per second\n",
        "    total_samples = batch_size * 1000 * n_runs\n",
        "    samples_per_second = total_samples / batch_time\n",
        "    samples_per_second_per_batch = samples_per_second / batch_size\n",
        "\n",
        "    # Measure sequential performance for small batches\n",
        "    if batch_size <= 10:\n",
        "        print(\"  Measuring sequential performance...\")\n",
        "        start_time = time.time()\n",
        "        for i in range(n_runs):\n",
        "            for j in range(batch_size):\n",
        "                subkey = random.fold_in(key, i*batch_size + j)\n",
        "                _ = jitted_sampler(subkey, batch_locs[j], batch_concentrations[j], (1000,))\n",
        "                _.block_until_ready()\n",
        "        seq_time = time.time() - start_time\n",
        "\n",
        "        seq_samples_per_second = total_samples / seq_time\n",
        "        speedup = seq_time / batch_time\n",
        "    else:\n",
        "        seq_samples_per_second = None\n",
        "        speedup = None\n",
        "\n",
        "    # Store results\n",
        "    batch_results.append({\n",
        "        'Batch Size': batch_size,\n",
        "        'Samples/Second': samples_per_second,\n",
        "        'Samples/Second/Batch': samples_per_second_per_batch,\n",
        "        'Sequential Samples/Second': seq_samples_per_second,\n",
        "        'Speedup': speedup\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_batch = pd.DataFrame(batch_results)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(df_batch['Batch Size'], df_batch['Samples/Second'], 'o-', linewidth=3, markersize=10, label='Total throughput')\n",
        "if df_batch['Sequential Samples/Second'].notna().any():\n",
        "    # Plot sequential performance where available\n",
        "    sequential_sizes = df_batch['Batch Size'][df_batch['Sequential Samples/Second'].notna()]\n",
        "    sequential_perf = df_batch['Sequential Samples/Second'][df_batch['Sequential Samples/Second'].notna()]\n",
        "    plt.plot(sequential_sizes, sequential_perf, 's--', linewidth=2, markersize=8, label='Sequential processing')\n",
        "\n",
        "plt.title('Batch Processing Performance with vmap')\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Samples per Second (higher is better)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/batch_processing_performance.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved batch processing performance plot to figures/batch_processing_performance.png\")\n",
        "plt.show()  # Comment out interactive display\n",
        "\n",
        "# Plot speedup\n",
        "plt.figure(figsize=(14, 6))\n",
        "speedup_df = df_batch[df_batch['Speedup'].notna()]\n",
        "plt.bar(speedup_df['Batch Size'].astype(str), speedup_df['Speedup'], color='steelblue')\n",
        "plt.title('Speedup from Batch Processing vs. Sequential Processing')\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Speedup Factor (higher is better)')\n",
        "for i, v in enumerate(speedup_df['Speedup']):\n",
        "    plt.text(i, v + 0.1, f\"{v:.1f}x\", ha='center')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/batch_processing_speedup.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved batch processing speedup plot to figures/batch_processing_speedup.png\")\n",
        "plt.show()  # Comment out interactive display\n"
      ],
      "metadata": {
        "id": "gwiti6Z_I7U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. First-Call Compilation Overhead\n",
        "\n",
        "JAX's JIT compilation has overhead on the first call. Let's measure this overhead:\n"
      ],
      "metadata": {
        "id": "N14i87y0JClW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Measuring JIT compilation overhead...\")\n",
        "\n",
        "# Fresh key and JIT function for clean measurement\n",
        "new_key = random.PRNGKey(100)\n",
        "fresh_jitted_sampler = jax.jit(sample_von_mises, static_argnums=(3,))\n",
        "\n",
        "# Measure first call time (includes compilation)\n",
        "start_time = time.time()\n",
        "first_samples = fresh_jitted_sampler(new_key, 0.0, 5.0, (10000,))\n",
        "first_samples.block_until_ready()\n",
        "first_call_time = time.time() - start_time\n",
        "\n",
        "# Measure subsequent call time\n",
        "start_time = time.time()\n",
        "second_samples = fresh_jitted_sampler(new_key, 0.0, 5.0, (10000,))\n",
        "second_samples.block_until_ready()\n",
        "second_call_time = time.time() - start_time\n",
        "\n",
        "# Calculate overhead\n",
        "overhead_factor = first_call_time / second_call_time\n",
        "\n",
        "print(f\"First call time (with compilation): {first_call_time:.4f} seconds\")\n",
        "print(f\"Second call time (no compilation): {second_call_time:.4f} seconds\")\n",
        "print(f\"Compilation overhead: {first_call_time - second_call_time:.4f} seconds\")\n",
        "print(f\"First call is {overhead_factor:.1f}x slower than subsequent calls\")\n",
        "\n",
        "# Create data for bar chart\n",
        "compilation_df = pd.DataFrame([\n",
        "    {'Call': 'First call (with compilation)', 'Time (seconds)': first_call_time},\n",
        "    {'Call': 'Subsequent call', 'Time (seconds)': second_call_time}\n",
        "])\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(compilation_df['Call'], compilation_df['Time (seconds)'], color=['lightcoral', 'steelblue'])\n",
        "plt.title('JIT Compilation Overhead')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add text labels\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "            f'{height:.4f}s', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/compilation_overhead.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved compilation overhead plot to figures/compilation_overhead.png\")\n",
        "plt.show()  # Comment out interactive display\n"
      ],
      "metadata": {
        "id": "TmGuie6mJFyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Key Takeaways\n",
        "\n",
        "Based on the benchmarks we've run, here are the key performance insights:\n",
        "\n",
        "1. **JIT Compilation Provides Dramatic Speedups**:\n",
        "   - JIT compilation speeds up von Mises sampling by **hundreds to thousands of times**\n",
        "   - The speedup increases with larger sample sizes\n",
        "\n",
        "2. **First-Call Compilation Overhead**:\n",
        "   - The first call to a JIT-compiled function includes compilation time\n",
        "   - Subsequent calls are much faster\n",
        "   - Consider \"warming up\" time-critical code with a small initial call\n",
        "\n",
        "3. **Concentration Parameter Impact**:\n",
        "   - Sampling performance varies with the concentration parameter (κ)\n",
        "   - Lower concentration values generally yield faster sampling\n",
        "   - The implementation optimizes special cases for very small and very large κ values\n",
        "\n",
        "4. **Batch Processing Benefits**:\n",
        "   - Using `vmap` provides significant speedups for processing multiple distributions\n",
        "   - Larger batch sizes generally improve throughput\n",
        "\n",
        "## 8. Best Practices\n",
        "\n",
        "To maximize performance with the JAX von Mises sampling library:\n",
        "\n",
        "1. **Always use JIT compilation with correct static arguments**:\n",
        "   ```python\n",
        "   jitted_sampler = jax.jit(sample_von_mises, static_argnums=(3,))\n",
        "   ```\n",
        "\n",
        "2. **Use warmup calls before time-critical operations**:\n",
        "   ```python\n",
        "   # Warmup with small size\n",
        "   _ = jitted_sampler(key, loc, concentration, shape=(10,))\n",
        "   # Actual computation\n",
        "   samples = jitted_sampler(key, loc, concentration, shape=(10000,))\n",
        "   ```\n",
        "\n",
        "3. **Batch process multiple distributions with vmap**:\n",
        "   ```python\n",
        "   batch_fn = jax.vmap(lambda k, l, c: sample_von_mises(k, l, c, shape=(1000,)))\n",
        "   jitted_batch_fn = jax.jit(batch_fn)\n",
        "   ```\n",
        "\n",
        "4. **Consider using GPU acceleration for even greater performance**:\n",
        "   ```python\n",
        "   # Install JAX with GPU support\n",
        "   # pip install \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "   ```\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The JAX von Mises sampling library delivers exceptional performance when used with JAX's transformations, particularly JIT compilation. For applications handling directional data, this library offers a high-performance solution that scales well to large sample sizes and batch processing requirements.\n"
      ],
      "metadata": {
        "id": "bJMaE2thJLAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF Calculation: von Mises Log Probability Density\n",
        "\n",
        "The library includes a `vmises_log_prob` function that calculates the log probability density. Let's visualize it:\n"
      ],
      "metadata": {
        "id": "RREwSnn_JPFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set parameters\n",
        "loc = 0.0\n",
        "kappa = 5.0\n",
        "\n",
        "# Generate x values\n",
        "x = np.linspace(-np.pi, np.pi, 1000)\n",
        "\n",
        "# Calculate log probability density\n",
        "log_prob = vmises_log_prob(x, loc, kappa)\n",
        "prob = np.exp(log_prob)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, prob, 'b-', linewidth=2)\n",
        "plt.fill_between(x, prob, alpha=0.3)\n",
        "plt.xlabel('Angle (radians)')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.title(f'Von Mises Probability Density (μ={loc}, κ={kappa})')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/von_mises_density.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved von Mises density plot to figures/von_mises_density.png\")\n",
        "# plt.show()  # Comment out interactive display\n"
      ],
      "metadata": {
        "id": "7rU1fX9iJSLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Entropy Calculation and Visualization\n",
        "\n",
        "The library also includes a `vmises_entropy` function for calculating the entropy of the von Mises distribution, which depends only on the concentration parameter κ.\n"
      ],
      "metadata": {
        "id": "zkRku5pMJWmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax_von_mises import vmises_entropy\n",
        "\n",
        "# Calculate entropy for different concentration values\n",
        "kappa_values = np.linspace(0.1, 20, 100)\n",
        "entropy_values = [vmises_entropy(k) for k in kappa_values]\n",
        "\n",
        "# Plot entropy vs concentration\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(kappa_values, entropy_values, 'b-', linewidth=2.5)\n",
        "plt.xlabel('Concentration Parameter (κ)')\n",
        "plt.ylabel('Entropy')\n",
        "plt.title('Von Mises Distribution Entropy')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Add annotation for maximum entropy\n",
        "max_entropy = np.log(2*np.pi)\n",
        "plt.axhline(y=max_entropy, color='r', linestyle='--',\n",
        "            label=f'Maximum entropy (uniform): {max_entropy:.4f}')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/entropy_vs_concentration.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved entropy vs concentration plot to figures/entropy_vs_concentration.png\")\n",
        "plt.show()  # Comment out interactive display"
      ],
      "metadata": {
        "id": "dP46GKNgJbE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The entropy is highest when κ=0 (uniform distribution) and decreases as κ increases. This reflects that a more concentrated distribution (higher κ) has lower uncertainty.\n",
        "\n",
        " ### Entropy Performance with JAX Transformations\n",
        "\n",
        " Let's compare the performance of entropy calculation with different JAX transformations:"
      ],
      "metadata": {
        "id": "UN3_roYnJkgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Prepare JAX transformations\n",
        "jitted_entropy = jax.jit(vmises_entropy)\n",
        "vmapped_entropy = jax.vmap(jitted_entropy)\n",
        "\n",
        "# Warm up JIT compilation\n",
        "_ = jitted_entropy(1.0)\n",
        "_ = vmapped_entropy(jnp.array([1.0]))\n",
        "\n",
        "# Test sizes\n",
        "sizes = [10, 100, 1000, 10000, 100000]\n",
        "results = []\n",
        "\n",
        "for size in sizes:\n",
        "    print(f\"Testing size: {size}\")\n",
        "\n",
        "    # Generate random concentration values\n",
        "    kappa_values = np.random.uniform(0.1, 10.0, size=size)\n",
        "    jax_kappa = jnp.array(kappa_values)\n",
        "\n",
        "    # Non-JIT timing\n",
        "    start = time.time()\n",
        "    for k in kappa_values:\n",
        "        _ = vmises_entropy(k)\n",
        "    nonjit_time = time.time() - start\n",
        "\n",
        "    # JIT timing\n",
        "    start = time.time()\n",
        "    for k in kappa_values:\n",
        "        _ = jitted_entropy(k).block_until_ready()\n",
        "    jit_time = time.time() - start\n",
        "\n",
        "    # vmap timing\n",
        "    start = time.time()\n",
        "    _ = vmapped_entropy(jax_kappa).block_until_ready()\n",
        "    vmap_time = time.time() - start\n",
        "\n",
        "    results.append({\n",
        "        'Size': size,\n",
        "        'Non-JIT (s)': nonjit_time,\n",
        "        'JIT (s)': jit_time,\n",
        "        'vmap (s)': vmap_time,\n",
        "        'JIT Speedup': nonjit_time / jit_time,\n",
        "        'vmap Speedup': nonjit_time / vmap_time\n",
        "    })\n",
        "\n",
        "    print(f\"  Non-JIT: {nonjit_time:.6f}s\")\n",
        "    print(f\"  JIT: {jit_time:.6f}s\")\n",
        "    print(f\"  vmap: {vmap_time:.6f}s\")\n",
        "    print(f\"  JIT Speedup: {nonjit_time / jit_time:.1f}x\")\n",
        "    print(f\"  vmap Speedup: {nonjit_time / vmap_time:.1f}x\")"
      ],
      "metadata": {
        "id": "nyLDquD3JqEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualize these results:\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Plot speedups\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['Size'], df['JIT Speedup'], 'b-o', linewidth=2, label='JIT Speedup')\n",
        "plt.plot(df['Size'], df['vmap Speedup'], 'r-s', linewidth=2, label='vmap Speedup')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Array Size')\n",
        "plt.ylabel('Speedup (x times faster)')\n",
        "plt.title('Entropy Calculation Speedup with JAX Transformations')\n",
        "plt.grid(True, which='both', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/entropy_speedup.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved entropy speedup plot to figures/entropy_speedup.png\")\n",
        "plt.show()  # Comment out interactive display\n"
      ],
      "metadata": {
        "id": "_tJhG4hSJsYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Automatic Differentiation with Entropy\n",
        "\n",
        "One of the most powerful features of JAX is automatic differentiation. Let's compute the gradient of entropy with respect to the concentration parameter\n"
      ],
      "metadata": {
        "id": "PHuPIR7bJyHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define gradient function\n",
        "grad_fn = jax.grad(vmises_entropy)\n",
        "jitted_grad = jax.jit(grad_fn)\n",
        "vmapped_grad = jax.vmap(jitted_grad)\n",
        "\n",
        "# Compute gradients for a range of concentration values\n",
        "kappa_values = np.linspace(0.1, 20, 100)\n",
        "entropy_values = vmapped_entropy(jnp.array(kappa_values))\n",
        "gradient_values = vmapped_grad(jnp.array(kappa_values))\n",
        "\n",
        "# Plot entropy and its gradient\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
        "\n",
        "# Entropy plot\n",
        "ax[0].plot(kappa_values, entropy_values, 'b-', linewidth=2, label='Entropy')\n",
        "ax[0].set_ylabel('Entropy')\n",
        "ax[0].set_title('Von Mises Entropy and its Gradient')\n",
        "ax[0].grid(alpha=0.3)\n",
        "ax[0].legend()\n",
        "\n",
        "# Gradient plot\n",
        "ax[1].plot(kappa_values, gradient_values, 'r-', linewidth=2, label='dEntropy/dκ')\n",
        "ax[1].set_xlabel('Concentration Parameter (κ)')\n",
        "ax[1].set_ylabel('Gradient')\n",
        "ax[1].grid(alpha=0.3)\n",
        "ax[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/entropy_gradient.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved entropy gradient plot to figures/entropy_gradient.png\")\n",
        "plt.show()  # Comment out interactive display"
      ],
      "metadata": {
        "id": "tTeQxYWcJxY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This ability to automatically compute derivatives is extremely useful for optimization problems, like finding the concentration parameter that gives a target entropy value. Let's demonstrate:\n"
      ],
      "metadata": {
        "id": "RQ8xQzlnKEPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import grad\n",
        "import jax.numpy as jnp\n",
        "import optax  # JAX's optimization library\n",
        "\n",
        "# Define a target entropy value\n",
        "target_entropy = 1.0\n",
        "\n",
        "# Define a loss function that measures the squared difference between current entropy and target\n",
        "def loss_fn(kappa):\n",
        "    entropy = vmises_entropy(kappa)\n",
        "    return (entropy - target_entropy) ** 2\n",
        "\n",
        "# Create gradient function\n",
        "loss_grad_fn = grad(loss_fn)\n",
        "\n",
        "# Initial concentration value\n",
        "kappa = jnp.array(5.0)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = optax.adam(learning_rate=0.1)\n",
        "opt_state = optimizer.init(kappa)\n",
        "\n",
        "# Run optimization for a few steps\n",
        "print(f\"Initial κ: {kappa:.4f}, Entropy: {vmises_entropy(kappa):.4f}, Target: {target_entropy:.4f}\")\n",
        "\n",
        "n_steps = 50\n",
        "kappa_history = [float(kappa)]\n",
        "entropy_history = [float(vmises_entropy(kappa))]\n",
        "loss_history = [float(loss_fn(kappa))]\n",
        "\n",
        "for i in range(n_steps):\n",
        "    # Compute gradient\n",
        "    grads = loss_grad_fn(kappa)\n",
        "\n",
        "    # Apply update\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    kappa = optax.apply_updates(kappa, updates)\n",
        "\n",
        "    # Ensure concentration stays positive\n",
        "    kappa = jnp.maximum(kappa, 0.001)\n",
        "\n",
        "    # Record history\n",
        "    kappa_history.append(float(kappa))\n",
        "    current_entropy = float(vmises_entropy(kappa))\n",
        "    entropy_history.append(current_entropy)\n",
        "    loss_history.append(float(loss_fn(kappa)))\n",
        "\n",
        "    if (i+1) % 10 == 0:\n",
        "        print(f\"Step {i+1}: κ = {kappa:.4f}, Entropy = {current_entropy:.4f}, Loss = {loss_history[-1]:.6f}\")\n"
      ],
      "metadata": {
        "id": "v59gb3ScKHSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's visualize the optimization progress:\n"
      ],
      "metadata": {
        "id": "acSyHN2AKKBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot optimization progress\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "# Concentration parameter\n",
        "ax[0].plot(range(n_steps+1), kappa_history, 'b-o', linewidth=2)\n",
        "ax[0].set_ylabel('Concentration (κ)')\n",
        "ax[0].set_title('Optimization Progress')\n",
        "ax[0].grid(alpha=0.3)\n",
        "\n",
        "# Entropy\n",
        "ax[1].plot(range(n_steps+1), entropy_history, 'g-s', linewidth=2)\n",
        "ax[1].axhline(y=target_entropy, color='r', linestyle='--', label=f'Target: {target_entropy}')\n",
        "ax[1].set_ylabel('Entropy')\n",
        "ax[1].grid(alpha=0.3)\n",
        "ax[1].legend()\n",
        "\n",
        "# Loss\n",
        "ax[2].plot(range(n_steps+1), loss_history, 'r-^', linewidth=2)\n",
        "ax[2].set_xlabel('Optimization Step')\n",
        "ax[2].set_ylabel('Loss')\n",
        "ax[2].set_yscale('log')\n",
        "ax[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "# Save figure to file\n",
        "plt.savefig('figures/entropy_optimization.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Saved entropy optimization plot to figures/entropy_optimization.png\")\n",
        "plt.show()  # Comment out interactive display"
      ],
      "metadata": {
        "id": "0ZXmBRRdKMBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates how our implementation enables gradient-based optimization of concentration parameters to achieve specific entropy targets - something that would be much more complex with SciPy's implementation.\n",
        "### Conclusion\n",
        "In this notebook, we've demonstrated:\n",
        "1. The von Mises sampling functionality with JAX transformations\n",
        "2. The dramatic performance improvements achieved with JIT compilation\n",
        "3. The ability to compute log probability density and entropy efficiently\n",
        "4. The power of automatic differentiation for optimization problems\n",
        "The JAX von Mises implementation provides a high-performance solution for directional statistics that leverages the full power of JAX's transformation system."
      ],
      "metadata": {
        "id": "rZvbaRg5KPh0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0KZAcI-YHzas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Example demonstrating the usage of von Mises entropy functions.\n",
        "\n",
        "This example shows how to use the JAX von Mises entropy function as a drop-in\n",
        "replacement for SciPy's implementation, with additional benefits of JAX transformations.\n",
        "\"\"\"\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import scipy.stats\n",
        "\n",
        "from jax_von_mises import vmises_entropy, vmises_log_prob\n",
        "\n",
        "# Set up the figure for comparison\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Concentration values for comparison\n",
        "kappa_values = np.linspace(0.1, 20, 100)\n",
        "\n",
        "# Computing entropy with SciPy\n",
        "start_time = time.time()\n",
        "scipy_entropy = np.array([scipy.stats.vonmises.entropy(kappa) for kappa in kappa_values])\n",
        "scipy_time = time.time() - start_time\n",
        "print(f\"SciPy computation time: {scipy_time:.6f} seconds\")\n",
        "\n",
        "# Computing entropy with JAX (non-JIT)\n",
        "start_time = time.time()\n",
        "jax_entropy = np.array([vmises_entropy(kappa) for kappa in kappa_values])\n",
        "jax_time = time.time() - start_time\n",
        "print(f\"JAX (non-JIT) computation time: {jax_time:.6f} seconds\")\n",
        "\n",
        "# Computing entropy with JAX (JIT)\n",
        "jitted_entropy = jax.jit(vmises_entropy)\n",
        "# Warmup call for compilation\n",
        "_ = jitted_entropy(1.0)\n",
        "start_time = time.time()\n",
        "jitted_jax_entropy = np.array([jitted_entropy(kappa).block_until_ready() for kappa in kappa_values])\n",
        "jit_time = time.time() - start_time\n",
        "print(f\"JAX (JIT) computation time: {jit_time:.6f} seconds\")\n",
        "print(f\"JIT speedup over non-JIT: {jax_time/jit_time:.2f}x\")\n",
        "\n",
        "# Computing entropy with JAX (vmap)\n",
        "vmapped_entropy = jax.vmap(jitted_entropy)\n",
        "start_time = time.time()\n",
        "vmapped_jax_entropy = vmapped_entropy(jnp.array(kappa_values)).block_until_ready()\n",
        "vmap_time = time.time() - start_time\n",
        "print(f\"JAX (vmap+JIT) computation time: {vmap_time:.6f} seconds\")\n",
        "print(f\"vmap speedup over JIT: {jit_time/vmap_time:.2f}x\")\n",
        "print(f\"Total JAX speedup over SciPy: {scipy_time/vmap_time:.2f}x\")\n",
        "\n",
        "# Plot the entropy values\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(kappa_values, scipy_entropy, 'r-', label='SciPy vonmises.entropy')\n",
        "plt.plot(kappa_values, jax_entropy, 'b--', label='JAX vmises_entropy')\n",
        "plt.plot(kappa_values, vmapped_jax_entropy, 'g:', label='JAX vmapped entropy')\n",
        "plt.xlabel('Concentration (κ)')\n",
        "plt.ylabel('Entropy')\n",
        "plt.title('Von Mises Entropy Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot the differences\n",
        "plt.subplot(2, 1, 2)\n",
        "diff_scipy_jax = np.abs(scipy_entropy - jax_entropy)\n",
        "diff_scipy_vmap = np.abs(scipy_entropy - vmapped_jax_entropy)\n",
        "plt.semilogy(kappa_values, diff_scipy_jax, 'b-', label='|SciPy - JAX|')\n",
        "plt.semilogy(kappa_values, diff_scipy_vmap, 'g-', label='|SciPy - JAX vmap|')\n",
        "plt.xlabel('Concentration (κ)')\n",
        "plt.ylabel('Absolute Difference (log scale)')\n",
        "plt.title('Difference Between Implementations')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Demonstration of vmises_entropy as a drop-in replacement\n",
        "print(\"\\nUsing JAX von Mises as a drop-in replacement for SciPy:\")\n",
        "\n",
        "# Create a function that would normally use SciPy's vonmises.entropy\n",
        "def analyze_directional_data_scipy(concentrations):\n",
        "    \"\"\"Analyze directional data using SciPy's implementation.\"\"\"\n",
        "    return {\n",
        "        'entropy': np.array([scipy.stats.vonmises.entropy(k) for k in concentrations]),\n",
        "        'mean_entropy': np.mean([scipy.stats.vonmises.entropy(k) for k in concentrations])\n",
        "    }\n",
        "\n",
        "# Create the same function using JAX's implementation as a drop-in replacement\n",
        "def analyze_directional_data_jax(concentrations):\n",
        "    \"\"\"Analyze directional data using JAX's implementation.\"\"\"\n",
        "    return {\n",
        "        'entropy': vmapped_entropy(jnp.array(concentrations)),\n",
        "        'mean_entropy': jnp.mean(vmapped_entropy(jnp.array(concentrations)))\n",
        "    }\n",
        "\n",
        "# Sample data for analysis\n",
        "sample_concentrations = np.array([0.5, 1.0, 2.0, 5.0, 10.0])\n",
        "\n",
        "# Run analysis with both implementations\n",
        "scipy_results = analyze_directional_data_scipy(sample_concentrations)\n",
        "jax_results = analyze_directional_data_jax(sample_concentrations)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nSciPy results:\")\n",
        "print(f\"Entropy values: {scipy_results['entropy']}\")\n",
        "print(f\"Mean entropy: {scipy_results['mean_entropy']}\")\n",
        "\n",
        "print(\"\\nJAX results:\")\n",
        "print(f\"Entropy values: {jax_results['entropy']}\")\n",
        "print(f\"Mean entropy: {jax_results['mean_entropy']}\")\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('entropy_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDemo showing how to use JAX entropy with gradients (not possible with SciPy):\")\n",
        "\n",
        "@jax.jit\n",
        "def loss_function(concentration, target_entropy):\n",
        "    \"\"\"Loss function based on entropy difference.\"\"\"\n",
        "    entropy = vmises_entropy(concentration)\n",
        "    return (entropy - target_entropy) ** 2\n",
        "\n",
        "# Get gradient function\n",
        "grad_fn = jax.grad(loss_function)\n",
        "\n",
        "# Target entropy\n",
        "target_entropy = 2.0\n",
        "\n",
        "# Calculate gradient\n",
        "concentration = 1.0\n",
        "gradient = grad_fn(concentration, target_entropy)\n",
        "print(f\"Gradient of loss w.r.t. concentration at κ={concentration}: {gradient}\")\n",
        "\n",
        "print(\"\\nConclusion:\")\n",
        "print(\"The JAX implementation of vmises_entropy is a drop-in replacement for SciPy's\")\n",
        "print(\"vonmises.entropy with additional benefits of JAX transformations like:\")\n",
        "print(\"  - JIT compilation for faster execution\")\n",
        "print(\"  - vmap for vectorized operations\")\n",
        "print(\"  - Automatic differentiation\")\n",
        "print(\"  - GPU/TPU acceleration\")"
      ],
      "metadata": {
        "id": "e2AvvbhABbW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0H9r9G4BdFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}